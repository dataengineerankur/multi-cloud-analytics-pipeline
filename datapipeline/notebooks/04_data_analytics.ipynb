{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38d469af-5bbe-41be-86d0-aa378ffd232b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Spark session initialized with Delta Lake and AWS S3 support\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Build the Spark Session using AWS Keys from Databricks Secrets\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PsychoBunny-DataIngestion\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", dbutils.secrets.get(scope=\"aws-keys\", key=\"aws-access-key\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", dbutils.secrets.get(scope=\"aws-keys\", key=\"aws-secret-key\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Spark session initialized with Delta Lake and AWS S3 support\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4745480-cfc7-4f88-9b87-594785788a42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "access = dbutils.secrets.get(\"aws-keys\", key=\"aws-access-key\")\n",
    "secret = dbutils.secrets.get(\"aws-keys\", key=\"aws-secret-key\")\n",
    "\n",
    "spark.conf.set(\"fs.s3a.access.key\", access)\n",
    "spark.conf.set(\"fs.s3a.secret.key\", secret)\n",
    "spark.conf.set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d20f298a-b65f-4d66-856e-3a5c9261ba90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅ Analytics Requirements notebook initialized\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Python Server ready to receive messages\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Loaded data: 2823 transactions, 2000 customers\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "RAW_DATA_PATH = \"s3://psycho-bunny-data-lake/raw-data/\"\n",
    "PROCESSED_DATA_PATH = \"s3://psycho-bunny-data-lake/processed-data/\"\n",
    "\n",
    "logger.info(\"Analytics Requirements notebook initialized\")\n",
    "\n",
    "# Load processed data from Delta Lake\n",
    "try:\n",
    "    fact_transactions = spark.read.format(\"delta\").load(f\"{PROCESSED_DATA_PATH}fact_transactions\")\n",
    "    dim_customer = spark.read.format(\"delta\").load(f\"{PROCESSED_DATA_PATH}dim_customer\")\n",
    "    dim_product = spark.read.format(\"delta\").load(f\"{PROCESSED_DATA_PATH}dim_product\")\n",
    "    calendar_df = spark.read.format(\"delta\").load(f\"{RAW_DATA_PATH}calendar\")\n",
    "    \n",
    "    logger.info(f\"Loaded data: {fact_transactions.count()} transactions, {dim_customer.count()} customers\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {str(e)}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b59097e-1b64-4744-a2cd-9b608fee8103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Sales Analytics: 1 records\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+----+-----------+------------+---------------+--------------------+\n|year|quarter|month|week|total_sales|total_orders|avg_order_value|        created_date|\n+----+-------+-----+----+-----------+------------+---------------+--------------------+\n|2025|      2|    6|  25|   282300.0|        2823|          100.0|2025-06-21 21:28:...|\n+----+-------+-----+----+-----------+------------+---------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Weekly, Monthly, Quarterly Sales Analysis\n",
    "sales_analytics = fact_transactions.filter(col(\"transaction_type\") == \"SALE\") \\\n",
    "    .withColumn(\"week\", weekofyear(col(\"order_date\"))) \\\n",
    "    .withColumn(\"month\", month(col(\"order_date\"))) \\\n",
    "    .withColumn(\"quarter\", quarter(col(\"order_date\"))) \\\n",
    "    .withColumn(\"year\", year(col(\"order_date\"))) \\\n",
    "    .groupBy(\"year\", \"quarter\", \"month\", \"week\") \\\n",
    "    .agg(\n",
    "        sum(\"net_amount\").alias(\"total_sales\"),\n",
    "        count(\"order_number\").alias(\"total_orders\"),\n",
    "        avg(\"net_amount\").alias(\"avg_order_value\")\n",
    "    ).withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Sales Analytics: {sales_analytics.count()} records\")\n",
    "sales_analytics.orderBy(desc(\"total_sales\")).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d6ed50a-4d90-49aa-8efd-47b3f37a6cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Refunds Analytics: 0 records\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+----+-------------+---------------------+-------------------+------------+\n|year|quarter|month|week|total_refunds|total_restocking_fees|total_refund_orders|created_date|\n+----+-------+-----+----+-------------+---------------------+-------------------+------------+\n+----+-------+-----+----+-------------+---------------------+-------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Weekly, Monthly, Quarterly Refunds Analysis\n",
    "refunds_analytics = fact_transactions.filter(col(\"transaction_type\") == \"REFUND\") \\\n",
    "    .withColumn(\"week\", weekofyear(col(\"order_date\"))) \\\n",
    "    .withColumn(\"month\", month(col(\"order_date\"))) \\\n",
    "    .withColumn(\"quarter\", quarter(col(\"order_date\"))) \\\n",
    "    .withColumn(\"year\", year(col(\"order_date\"))) \\\n",
    "    .groupBy(\"year\", \"quarter\", \"month\", \"week\") \\\n",
    "    .agg(\n",
    "        sum(\"net_amount\").alias(\"total_refunds\"),\n",
    "        sum(\"restocking_fee\").alias(\"total_restocking_fees\"),\n",
    "        count(\"order_number\").alias(\"total_refund_orders\")\n",
    "    ).withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Refunds Analytics: {refunds_analytics.count()} records\")\n",
    "refunds_analytics.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e1b48d-d093-4165-8e45-2ad6c371ade9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Product Family Sales: 8 families\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+------------+---------------+--------------------+\n|product_family|total_sales|total_orders|avg_order_value|        created_date|\n+--------------+-----------+------------+---------------+--------------------+\n|           S18|    99500.0|         995|          100.0|2025-06-21 21:29:...|\n|           S24|    73100.0|         731|          100.0|2025-06-21 21:29:...|\n|          S700|    31300.0|         313|          100.0|2025-06-21 21:29:...|\n|           S12|    25900.0|         259|          100.0|2025-06-21 21:29:...|\n|           S32|    20600.0|         206|          100.0|2025-06-21 21:29:...|\n|           S10|    16100.0|         161|          100.0|2025-06-21 21:29:...|\n|           S50|    10500.0|         105|          100.0|2025-06-21 21:29:...|\n|           S72|     5300.0|          53|          100.0|2025-06-21 21:29:...|\n+--------------+-----------+------------+---------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Product Family Analysis - Extract from product codes\n",
    "def extract_product_family(product_code):\n",
    "    \"\"\"Extract product family from product code\"\"\"\n",
    "    if product_code and \"_\" in product_code:\n",
    "        return product_code.split(\"_\")[0]\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "extract_family_udf = udf(extract_product_family, StringType())\n",
    "\n",
    "# Product family sales analysis\n",
    "product_family_sales = fact_transactions.filter(col(\"transaction_type\") == \"SALE\") \\\n",
    "    .withColumn(\"product_family\", extract_family_udf(col(\"product_code\"))) \\\n",
    "    .groupBy(\"product_family\") \\\n",
    "    .agg(\n",
    "        sum(\"net_amount\").alias(\"total_sales\"),\n",
    "        count(\"order_number\").alias(\"total_orders\"),\n",
    "        avg(\"net_amount\").alias(\"avg_order_value\")\n",
    "    ).orderBy(desc(\"total_sales\")) \\\n",
    "    .withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Product Family Sales: {product_family_sales.count()} families\")\n",
    "product_family_sales.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e645386-ddf2-42ba-bef0-f7251619260d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Regional Rankings: 6 records\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------------+-----------+------------+----+-------------------+--------------------+\n|territory|product_code|product_family|total_sales|total_orders|rank|       ranking_type|        created_date|\n+---------+------------+--------------+-----------+------------+----+-------------------+--------------------+\n|    Large|    S10_1949|           S10|     1400.0|          14|   1|       Best Selling|2025-06-21 21:31:...|\n|    Large|    S18_3232|           S18|     1400.0|          14|   2|Second Best Selling|2025-06-21 21:31:...|\n|   Medium|    S18_3232|           S18|     3400.0|          34|   1|       Best Selling|2025-06-21 21:31:...|\n|   Medium|    S18_1129|           S18|     2300.0|          23|   2|Second Best Selling|2025-06-21 21:31:...|\n|    Small|    S24_1444|           S24|     2600.0|          26|   1|       Best Selling|2025-06-21 21:31:...|\n|    Small|    S18_2432|           S18|     2500.0|          25|   2|Second Best Selling|2025-06-21 21:31:...|\n+---------+------------+--------------+-----------+------------+----+-------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 4. Best-selling and Second Best-selling Items by Region\n",
    "regional_product_sales = fact_transactions.filter(col(\"transaction_type\") == \"SALE\") \\\n",
    "    .withColumn(\"product_family\", extract_family_udf(col(\"product_code\"))) \\\n",
    "    .groupBy(\"territory\", \"product_code\", \"product_family\") \\\n",
    "    .agg(\n",
    "        sum(\"net_amount\").alias(\"total_sales\"),\n",
    "        count(\"order_number\").alias(\"total_orders\")\n",
    "    )\n",
    "\n",
    "# Window function to rank products by sales within each territory\n",
    "window_spec = Window.partitionBy(\"territory\").orderBy(desc(\"total_sales\"))\n",
    "\n",
    "regional_rankings = regional_product_sales.withColumn(\n",
    "    \"rank\", row_number().over(window_spec)\n",
    ").filter(col(\"rank\") <= 2) \\\n",
    ".withColumn(\"ranking_type\", \n",
    "    when(col(\"rank\") == 1, \"Best Selling\")\n",
    "    .when(col(\"rank\") == 2, \"Second Best Selling\")\n",
    "    .otherwise(\"Other\")\n",
    ").withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Regional Rankings: {regional_rankings.count()} records\")\n",
    "regional_rankings.show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f898d8b-a08d-40d6-a88f-f6c2d2f203dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Revenue Difference Analysis: 3 territories\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------------------+------------------+----------------------+--------------------+\n|territory|best_selling_revenue|second_best_revenue|revenue_difference|revenue_difference_pct|        created_date|\n+---------+--------------------+-------------------+------------------+----------------------+--------------------+\n|    Large|              1400.0|             1400.0|               0.0|                   0.0|2025-06-21 21:32:...|\n|   Medium|              3400.0|             2300.0|            1100.0|                 32.35|2025-06-21 21:32:...|\n|    Small|              2600.0|             2500.0|             100.0|                  3.85|2025-06-21 21:32:...|\n+---------+--------------------+-------------------+------------------+----------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Revenue Difference Between Best and Second Best Items per Region\n",
    "revenue_difference = regional_rankings.groupBy(\"territory\") \\\n",
    "    .agg(\n",
    "        max(when(col(\"rank\") == 1, col(\"total_sales\"))).alias(\"best_selling_revenue\"),\n",
    "        max(when(col(\"rank\") == 2, col(\"total_sales\"))).alias(\"second_best_revenue\")\n",
    "    ).withColumn(\n",
    "        \"revenue_difference\", \n",
    "        col(\"best_selling_revenue\") - col(\"second_best_revenue\")\n",
    "    ).withColumn(\n",
    "        \"revenue_difference_pct\",\n",
    "        round((col(\"revenue_difference\") / col(\"best_selling_revenue\")) * 100, 2)\n",
    "    ).withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Revenue Difference Analysis: {revenue_difference.count()} territories\")\n",
    "revenue_difference.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29c46d16-3200-487b-8285-d95191cad020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Enhanced Customer Segments: 1 customers\nINFO:__main__:Thresholds: Low: <$282300.00, Medium: $282300.00-$282300.00, High: >$282300.00\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n|customer_segment|count|\n+----------------+-----+\n|      High Value|    1|\n+----------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Enhanced Customer Segmentation (High, Medium, Low Value)\n",
    "customer_metrics = fact_transactions.filter(col(\"transaction_type\") == \"SALE\") \\\n",
    "    .groupBy(\"customer_name\") \\\n",
    "    .agg(\n",
    "        sum(\"net_amount\").alias(\"total_spent\"),\n",
    "        count(\"order_number\").alias(\"total_orders\"),\n",
    "        avg(\"net_amount\").alias(\"avg_order_value\"),\n",
    "        max(\"order_date\").alias(\"last_order_date\"),\n",
    "        countDistinct(\"product_code\").alias(\"unique_products_purchased\")\n",
    "    )\n",
    "\n",
    "# Calculate percentiles for segmentation\n",
    "percentiles = customer_metrics.select(\n",
    "    expr(\"percentile_approx(total_spent, 0.33)\").alias(\"p33\"),\n",
    "    expr(\"percentile_approx(total_spent, 0.67)\").alias(\"p67\")\n",
    ").collect()[0]\n",
    "\n",
    "p33_threshold = percentiles[\"p33\"]\n",
    "p67_threshold = percentiles[\"p67\"]\n",
    "\n",
    "enhanced_customer_segments = customer_metrics.withColumn(\n",
    "    \"customer_segment\",\n",
    "    when(col(\"total_spent\") >= p67_threshold, \"High Value\")\n",
    "    .when(col(\"total_spent\") >= p33_threshold, \"Medium Value\")\n",
    "    .otherwise(\"Low Value\")\n",
    ").withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Enhanced Customer Segments: {enhanced_customer_segments.count()} customers\")\n",
    "logger.info(f\"Thresholds: Low: <${p33_threshold:.2f}, Medium: ${p33_threshold:.2f}-${p67_threshold:.2f}, High: >${p67_threshold:.2f}\")\n",
    "enhanced_customer_segments.groupBy(\"customer_segment\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fca0bd4-4ff9-4d40-bfca-186fa9a20273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Top Customers with Contact Details: 1 customers\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------+---------+-----+-----------+------------+---------------+-------------------------+----------------+\n|customer_name|               email|       phone|     city|state|total_spent|total_orders|avg_order_value|unique_products_purchased|customer_segment|\n+-------------+--------------------+------------+---------+-----+-----------+------------+---------------+-------------------------+----------------+\n| Aaron Kloska|aaron_kloska@klos...|07-9896-4827|Brookhill|  QLD|   282300.0|        2823|          100.0|                      109|      High Value|\n+-------------+--------------------+------------+---------+-----+-----------+------------+---------------+-------------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Top 10 Customers by Segment with Contact Details\n",
    "top_customers_by_segment = enhanced_customer_segments.join(\n",
    "    dim_customer.select(\"full_name\", \"email\", \"phone\", \"city\", \"state\"),\n",
    "    enhanced_customer_segments.customer_name == dim_customer.full_name,\n",
    "    \"left\"\n",
    ").select(\n",
    "    \"customer_name\", \"email\", \"phone\", \"city\", \"state\",\n",
    "    \"total_spent\", \"total_orders\", \"avg_order_value\", \n",
    "    \"unique_products_purchased\", \"customer_segment\"\n",
    ").orderBy(desc(\"total_spent\"))\n",
    "\n",
    "logger.info(f\"Top Customers with Contact Details: {top_customers_by_segment.count()} customers\")\n",
    "top_customers_by_segment.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "778e9d26-9cc4-45d9-8ac3-760f960e9fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅ Refund UDF with 10% restocking fee implemented\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------------+-------------+------------+------------+------+----------+----------------+--------------+----------+--------------+------------+---------+------------------+-----------------------+-------------------------+\n|product_code|territory|customer_key|customer_name|order_number|total_amount|status|order_date|transaction_type|restocking_fee|net_amount|is_large_order|created_date|is_refund|refund_calculation|calculated_final_amount|calculated_restocking_fee|\n+------------+---------+------------+-------------+------------+------------+------+----------+----------------+--------------+----------+--------------+------------+---------+------------------+-----------------------+-------------------------+\n+------------+---------+------------+-------------+------------+------------+------+----------+----------------+--------------+----------+--------------+------------+---------+------------------+-----------------------+-------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8. Refund UDF with 10% Restocking Fee\n",
    "def calculate_refund_with_fee(original_amount, is_refund):\n",
    "    \"\"\"Calculate final refund amount with 10% restocking fee\"\"\"\n",
    "    if is_refund:\n",
    "        restocking_fee = float(original_amount) * 0.10\n",
    "        final_refund = float(original_amount) - restocking_fee\n",
    "        return final_refund, restocking_fee\n",
    "    return float(original_amount), 0.0\n",
    "\n",
    "calculate_refund_udf = udf(calculate_refund_with_fee, StructType([\n",
    "    StructField(\"final_amount\", DoubleType(), True),\n",
    "    StructField(\"restocking_fee\", DoubleType(), True)\n",
    "]))\n",
    "\n",
    "# Enhanced refund analysis\n",
    "refund_analysis = fact_transactions.withColumn(\n",
    "    \"is_refund\", col(\"transaction_type\") == \"REFUND\"\n",
    ").withColumn(\n",
    "    \"refund_calculation\", calculate_refund_udf(col(\"total_amount\"), col(\"is_refund\"))\n",
    ").select(\n",
    "    \"*\",\n",
    "    col(\"refund_calculation.final_amount\").alias(\"calculated_final_amount\"),\n",
    "    col(\"refund_calculation.restocking_fee\").alias(\"calculated_restocking_fee\")\n",
    ")\n",
    "\n",
    "logger.info(\"Refund UDF with 10% restocking fee implemented\")\n",
    "refund_analysis.filter(col(\"transaction_type\") == \"REFUND\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "212f6f9c-acdb-4aa2-9ab2-ec8e9e21be15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:__main__:✅ Fiscal Aggregations: 1 records\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\nINFO:py4j.clientserver:Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------------+------------+-------------+----------------+--------------------+\n|FISCAL_YEAR|FISCAL_QUARTER|FISCAL_MONTH_NAME|fiscal_sales|fiscal_orders|fiscal_avg_order|        created_date|\n+-----------+--------------+-----------------+------------+-------------+----------------+--------------------+\n|       2025|             2|              Jun|    282300.0|         2823|           100.0|2025-06-21 21:34:...|\n+-----------+--------------+-----------------+------------+-------------+----------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Fiscal Date Aggregations using Calendar Dimension\n",
    "fiscal_aggregations = fact_transactions.filter(col(\"transaction_type\") == \"SALE\") \\\n",
    "    .join(calendar_df, date_format(fact_transactions.order_date, \"yyyy-MM-dd\") == calendar_df.CALENDAR_DATE, \"left\") \\\n",
    "    .groupBy(\"FISCAL_YEAR\", \"FISCAL_QUARTER\", \"FISCAL_MONTH_NAME\") \\\n",
    "    .agg(\n",
    "        sum(\"net_amount\").alias(\"fiscal_sales\"),\n",
    "        count(\"order_number\").alias(\"fiscal_orders\"),\n",
    "        avg(\"net_amount\").alias(\"fiscal_avg_order\")\n",
    "    ).orderBy(\"FISCAL_YEAR\", \"FISCAL_QUARTER\") \\\n",
    "    .withColumn(\"created_date\", current_timestamp())\n",
    "\n",
    "logger.info(f\"Fiscal Aggregations: {fiscal_aggregations.count()} records\")\n",
    "fiscal_aggregations.show(10)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_data_analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}